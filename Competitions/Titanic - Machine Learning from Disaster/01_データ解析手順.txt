タイタニックデータ解析チートシート

1．pythonで利用するデータ分析のパッケージの選定
  パッケージ一覧
  　numpy
  　pandas
  　pandas-profiling
  　matplotlib
  　seaboorn
  　
2. データの読み込み
　提供されているCSVデータをpdライブラリで読み込み

3. データの可視化
　データの概要を確認
　　列→　カラム名、データ型（整数、小数、bool型、object型、float型など）
　　　　　カテゴリデータなのか
　　行→　全体の件数　
　　　　　欠損値があるか、カラム毎の欠損値の数を確認、どのカラムが欠損値が多いのか

　要約統計量を調べる
　　データ数、平均、標準偏差、最小値、最大値、四分位数（ローソク）
　　
　　重複データの確認
　　
　　※train、testデータを結合させて調べる　
　　trainデータとは
　　

　　testデータとは


　　要約統計量のデータからデータの傾向を分析
　　　　生存した人はどれくらいいたのか
　　　　乗客の平均年齢は
　　　　高齢、若年の年齢は
　　　　
　　pandas-profilingを利用してデータ概要を調べる
　　　データ出力された見方はここを参照
　　　variablesで統計量やヒストグラム等が表示される
　　　
　　　Overview(概要)
　　　Variables(特徴量の情報)
　　　Interactions(散布図)
　　　Correlations(相関)
　　　Missing valus(欠損値の情報)
　　　　　Count:欠損値の数,Matrix：欠損値の場所,Heatmap：欠損値の相関度のヒートマップ,Dendrogram：欠損値の相関の近さ
　　　Sample(実データ)
　　　　　先頭10行、最後の10行が表示


　　データの関係を可視化
　　　可視化するためのツール
　　　　matplotlib.pyplot、seaborn、japaneze_matplotlib

　　タイタニックの例
　　　生存者・死亡者数の割合を可視化（グラフ化）
　　　男女別の生存者数、死亡者数の確認、クロス集計、　
　　　チケットクラス別の死亡者数、生存者数
　　　年齢別の生存者数、死亡者数
　　　同乗している兄弟、配偶者の数別の死亡者と生存者数
　　　一人or二人以上で乗船別の死亡者と生存者の数

4. LightGBMで機械学習
　　マイクロソフトが開発したライブラリ
　　アルゴリズムは、決定木ベースの勾配ブースティング
　　決定木：「男か女か」、「10歳以上か未満か」、トレーニングデータを当てはまりがよいように分割
　　　　　　その分割結果をグループ毎に、分類結果を出力するアルゴリズム　　

　1. データの前処理
　　　データ予測できる形にすることの前処理、前処理によって結果が左右される重要な工程
　　　やること
　　　　欠損値の対応、外れ値の検出・処理、ダミー変数の作成、連続データの離散化、特徴量選択

　　　　カテゴリ変数の変換→例えば「性別」は「sex_famale」、「sex_male」のカラムに分割して該当する値に1をいれる
　　　　※カテゴリ変数とはカテゴリ間の大小関係がないこと、文字として扱うのがで難しいのでデータを変換する
　　　　
　　　　不要な特徴量は列の削除する
　　　　↑
　　　　これまでの過程をOne-Hotエンコーディングという
　　　　
　　　　カテゴリ変数として指定する場合は０から始まる連続した整数に変換する場合もある
　　　　※One-Hotエンコーディングよりパフォーマンスが良い場合がある

　2. LightGBMでtrainデータを学習
　　　ホールドアウト法で学習
　　　　67%と33％の割合でtrainセットとvalidセット（検証セット）に分割
　　　　67％で学習、33％で予測　

　　　「feature_importance」で特徴の重要度を取得
　　　　
　
　3. testデータで生存予測

　4.精度がでない場合はk分割交差検証


　　
　　　

　　　
　　


　　　　　　
　
　　　　　
　　　　　
　　　　
　　　　
